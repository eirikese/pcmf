{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "# data = pd.read_csv('eval_data_2024-04-12-14-35-21_s50.csv')  # Brattorkaia, works best!\n",
    "# data = pd.read_csv('eval_data_2024-04-25-13-43-12.bag -s 60.csv')  # Bridge run 1, successful! ish 8m error, messy path\n",
    "# data = pd.read_csv('eval_data_2024-04-05-13-16-20.bag_low_tide.csv')  # +3s brattora, low tide, 5m mean error\n",
    "# data = pd.read_csv('eval_data_2024-04-12-14-35-21.bag -s 60 mid_tide.csv')  # +3s brattora, mid tide, 5m mean error\n",
    "# data = pd.read_csv('eval_data_2024-04-12-15-04-39.bag -s 30 high tide.csv')  # +3s brattora, high tide, 5-6m mean error\n",
    "# data = pd.read_csv('eval_data_2024-04-12-14-26-20.bag -s 30 mid tide.csv')  # +3s brattora, mid tide, 4-5m mean error\n",
    "data = pd.read_csv('eval_data.csv')  # latest log\n",
    "\n",
    "# adjust timeframe to start at 0\n",
    "data['timestamp'] = data['timestamp'] - data['timestamp'].min()\n",
    "\n",
    "# set time limits\n",
    "start_time = 0\n",
    "end_time = data['timestamp'].max() # - 20\n",
    "\n",
    "# filter rows with nans in transformation_history_x/y and gps/local_fix_x/y\n",
    "data = data.dropna(subset=['transformation_history_x', 'transformation_history_y', 'gps/local_fix_x', 'gps/local_fix_y'])\n",
    "\n",
    "# print nans\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# filter data\n",
    "data = data[(data['timestamp'] >= start_time) & (data['timestamp'] <= end_time)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Position and error plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the local fix and path points\n",
    "fig, ax = plt.subplots(3, 1, figsize=(12, 12))\n",
    "\n",
    "# First subplot for the paths in xy plane\n",
    "ax[0].scatter(data['gps/local_fix_x'].to_numpy(), data['gps/local_fix_y'].to_numpy(), label='GPS Path', color='lightblue', s = 5)\n",
    "ax[0].scatter(data['path_points_x'].to_numpy(), data['path_points_y'].to_numpy(), label='PCMF path points', color='orange', s = 5)\n",
    "ax[0].set_xlabel('X Position')\n",
    "ax[0].set_ylabel('Y Position')\n",
    "ax[0].set_title('Paths in XY plane')\n",
    "ax[0].legend()\n",
    "ax[0].grid(True)\n",
    "# equal aspect ratio and scaling\n",
    "ax[0].set_aspect('equal', 'box')\n",
    "\n",
    "# Draw error lines between the points\n",
    "# for i in range(len(data)):\n",
    "#     ax[0].plot([data['gps/local_fix_x'].iloc[i], data['path_points_x'].iloc[i]], \n",
    "#                [data['gps/local_fix_y'].iloc[i], data['path_points_y'].iloc[i]], \n",
    "#                'lightgrey', linestyle='dotted')\n",
    "\n",
    "# Second subplot for error over time\n",
    "errors = np.sqrt((data['gps/local_fix_x'] - data['path_points_x'])**2 + (data['gps/local_fix_y'] - data['path_points_y'])**2)\n",
    "ax[1].plot(data['timestamp'].to_numpy(), errors.to_numpy(), label='Error Over Time', color='red')\n",
    "ax[1].set_xlabel('Timestamp')\n",
    "ax[1].set_ylabel('Error')\n",
    "ax[1].set_title('Error Over Time')\n",
    "ax[1].grid(True)\n",
    "ax[1].legend()\n",
    "\n",
    "# Third subplot for boxplot of errors\n",
    "ax[2].boxplot(errors, vert=False, patch_artist=True)\n",
    "ax[2].set_title('Boxplot of Errors')\n",
    "ax[2].set_xlabel('Error')\n",
    "ax[2].grid(True)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout(h_pad=5.0, pad=3.0, w_pad=3.0)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import numpy as np\n",
    "from matplotlib.patches import Ellipse\n",
    "from filterpy.kalman import UnscentedKalmanFilter, MerweScaledSigmaPoints\n",
    "\n",
    "def plot_covariance_ellipse(ax, mean, cov, n_std=2, **kwargs):\n",
    "    \"\"\" Plots an ellipse representing the covariance matrix \"\"\"\n",
    "    eigvals, eigvecs = np.linalg.eigh(cov[:2, :2])  # extract covariance of x and y\n",
    "    order = eigvals.argsort()[::-1]\n",
    "    eigvals, eigvecs = eigvals[order], eigvecs[:, order]\n",
    "    theta = np.degrees(np.arctan2(*eigvecs[:, 0][::-1]))\n",
    "    w, h = 2 * n_std * np.sqrt(eigvals)\n",
    "    ellipse = Ellipse(xy=(mean[0], mean[2]), width=(w+h)/2, height=(w+h)/2, angle=theta, **kwargs)\n",
    "    ellipse.set_label('Covariance')\n",
    "    ax.add_patch(ellipse)\n",
    "\n",
    "def fx(x, dt):\n",
    "    \"\"\" State transition function for a constant velocity model \"\"\"\n",
    "    F = np.array([[1, dt, 0,  0], \n",
    "                  [0,  1, 0,  0], \n",
    "                  [0,  0, 1, dt],\n",
    "                  [0,  0, 0,  1]])\n",
    "    return np.dot(F, x)\n",
    "\n",
    "def hx(x):\n",
    "    \"\"\" Observation function - here we're only observing positions \"\"\"\n",
    "    return np.array([x[0], x[2]])\n",
    "\n",
    "def UKF(data):\n",
    "\n",
    "    # UKF Initialization\n",
    "    dt = 1  # time step\n",
    "    points = MerweScaledSigmaPoints(4, alpha=0.1, beta=2., kappa=-1)\n",
    "    ukf = UnscentedKalmanFilter(dim_x=4, dim_z=2, dt=dt, fx=fx, hx=hx, points=points)\n",
    "    process_noise = 0.01\n",
    "    ukf.Q = np.diag([process_noise, process_noise, process_noise, process_noise])  # process noise\n",
    "    ukf.R = np.diag([100, 100])                # initial measurement noise\n",
    "    ukf.x = np.array([data['path_points_x'].iloc[0], 0., data['path_points_y'].iloc[0], 0.])  # initial state\n",
    "    ukf.P = np.eye(4) * 100                # initial uncertainty\n",
    "\n",
    "    # Extract path points\n",
    "    path_x = data['path_points_x'].values\n",
    "    path_y = data['path_points_y'].values\n",
    "\n",
    "    # Apply UKF and store results, innovation\n",
    "    ukf_results = []\n",
    "    covariances = []\n",
    "\n",
    "    for px, py in zip(path_x, path_y):\n",
    "        ukf.predict()\n",
    "        z = np.array([px, py])\n",
    "        z_pred = ukf.hx(ukf.x)\n",
    "        innovation = z - z_pred\n",
    "        if np.linalg.norm(innovation) > 30:  # Threshold for detecting large jumps\n",
    "            ukf.R = np.diag([100000, 100000])  # Increase measurement noise\n",
    "        else:\n",
    "            ukf.R = np.diag([100, 100])  # Normal measurement noise\n",
    "        \n",
    "        ukf.update(z)\n",
    "        ukf_results.append(ukf.x.copy())\n",
    "        covariances.append(ukf.P.copy())\n",
    "\n",
    "\n",
    "\n",
    "    ukf_results = np.array(ukf_results)\n",
    "    covariances = np.array(covariances)\n",
    "\n",
    "    return ukf_results, covariances\n",
    "\n",
    "# Load map data\n",
    "map_file_path = r\"C:\\Users\\eirik\\OneDrive - NTNU\\Semester 10\\code\\lidar_ws\\src\\pcmf\\maps\\all_points.npy\" # bridge map data\n",
    "# map_file_path = \"/home/eirik/lidar_ws/src/pcmf/maps/bay_lines_v3.npy\" # brattorkaia map data\n",
    "map_data = np.load(map_file_path)\n",
    "\n",
    "# shift map data 200m left\n",
    "map_data[:, 0] = map_data[:, 0] # - 200\n",
    "\n",
    "# Apply UKF\n",
    "ukf_results, covariances = UKF(data)\n",
    "\n",
    "# plot parameters\n",
    "dot_size = 9\n",
    "map_dot_size = 1\n",
    "y_window_shift = 70\n",
    "gps_color = 'hotpink'\n",
    "# pcmf_color = 'lightblue'\n",
    "pcmf_color = 'lightskyblue'\n",
    "# ukf_color = 'steelblue'\n",
    "ukf_color = 'navy'\n",
    "map_color = 'orange'\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.scatter(data['path_points_x'], data['path_points_y'], label='PCMF Path Points', color=pcmf_color, s=dot_size)\n",
    "ax.plot(ukf_results[:, 0], ukf_results[:, 2], color=ukf_color, label=\"UKF Filtered Path Points\")\n",
    "ax.scatter(data['gps/local_fix_x'], data['gps/local_fix_y'], color=gps_color, label='GPS Path', s=dot_size)\n",
    "ax.scatter(map_data[:, 0], map_data[:, 1], color=map_color, s=map_dot_size, label='Reference Map')\n",
    "ax.set_xlabel(\"East [m]\")\n",
    "ax.set_ylabel(\"North [m]\")\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(True, linestyle='--' )\n",
    "ax.axis('equal')\n",
    "ax.set_ylim(ax.get_ylim()[0] - y_window_shift, ax.get_ylim()[1] - y_window_shift)\n",
    "\n",
    "# Add inset of zoomed area at the determined location\n",
    "axins = inset_axes(ax, width=\"50%\", height=\"50%\", loc='lower right')\n",
    "axins.scatter(data['path_points_x'], data['path_points_y'], label='PCMF Path Points', color=pcmf_color, s=dot_size)\n",
    "axins.plot(ukf_results[:, 0], ukf_results[:, 2], color=ukf_color, label=\"UKF Filtered Path Points\")\n",
    "axins.scatter(data['gps/local_fix_x'], data['gps/local_fix_y'], color=gps_color, label='GPS Path', s=dot_size)\n",
    "padding = 5\n",
    "x1, x2 = ukf_results[:, 0].min() - padding, ukf_results[:, 0].max() + padding\n",
    "y1, y2 = ukf_results[:, 2].min() - padding, ukf_results[:, 2].max() + padding\n",
    "axins.set_aspect('equal', adjustable='box')\n",
    "axins.set_xlim(x1, x2)\n",
    "axins.set_ylim(y1, y2)\n",
    "\n",
    "# Plot covariance ellipses every N=10 steps\n",
    "for i in range(0, len(ukf_results), 5):\n",
    "    plot_covariance_ellipse(axins, ukf_results[i], covariances[i], edgecolor='grey', facecolor='none', linestyle='--', alpha=0.5)\n",
    "# for i in range(0, len(ukf_results), 10000):\n",
    "#     plot_covariance_ellipse(ax, ukf_results[i], covariances[i], edgecolor='grey', facecolor='none', linestyle='--', alpha=0.5)\n",
    "\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the individual X and Y errors as well as Euclidean for GPS vs PCMF and GPS vs UKF\n",
    "error_x_gps_pcmf = np.abs(data['gps/local_fix_x'] - data['path_points_x'])\n",
    "error_y_gps_pcmf = np.abs(data['gps/local_fix_y'] - data['path_points_y'])\n",
    "euclidean_gps_pcmf = np.sqrt(error_x_gps_pcmf**2 + error_y_gps_pcmf**2)\n",
    "\n",
    "error_x_gps_ukf = np.abs(data['gps/local_fix_x'] - ukf_results[:, 0])\n",
    "error_y_gps_ukf = np.abs(data['gps/local_fix_y'] - ukf_results[:, 2])\n",
    "euclidean_gps_ukf = np.sqrt(error_x_gps_ukf**2 + error_y_gps_ukf**2)\n",
    "\n",
    "# Define function to calculate the IQR range for zoom limits\n",
    "def iqr_limits(data):\n",
    "    q1 = np.percentile(data, 25)\n",
    "    q3 = np.percentile(data, 75)\n",
    "    iqr = q3 - q1\n",
    "    return q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "\n",
    "# Plotting the RMSE boxplots with IQR zoom\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "# Full range plots\n",
    "axs[0, 0].boxplot([error_x_gps_pcmf, error_y_gps_pcmf, euclidean_gps_pcmf], labels=['Error X', 'Error Y', 'Euclidean Error'])\n",
    "axs[0, 0].set_title('Full Range GPS vs PCMF Points')\n",
    "axs[0, 1].boxplot([error_x_gps_ukf, error_y_gps_ukf, euclidean_gps_ukf], labels=['Error X', 'Error Y', 'Euclidean Error'])\n",
    "axs[0, 1].set_title('Full Range GPS vs UKF PCMF Points')\n",
    "#set colors for the boxes and whiskers and caps according to the color of the points\n",
    "\n",
    "# IQR zoomed plots\n",
    "lower_pcmf, upper_pcmf = iqr_limits(euclidean_gps_pcmf)\n",
    "lower_ukf, upper_ukf = iqr_limits(euclidean_gps_ukf)\n",
    "\n",
    "axs[1, 0].boxplot([error_x_gps_pcmf, error_y_gps_pcmf, euclidean_gps_pcmf], labels=['Error X', 'Error Y', 'Euclidean Error'])\n",
    "axs[1, 0].set_ylim(-1, upper_pcmf + 1)\n",
    "axs[1, 0].set_title('IQR-range GPS vs PCMF Points')\n",
    "\n",
    "axs[1, 1].boxplot([error_x_gps_ukf, error_y_gps_ukf, euclidean_gps_ukf], labels=['Error X', 'Error Y', 'Euclidean Error'])\n",
    "axs[1, 1].set_ylim(-1, upper_ukf + 1)\n",
    "axs[1, 1].set_title('IQR-range GPS vs UKF PCMF Points')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set_ylabel('Error (meters)')\n",
    "\n",
    "# plt.suptitle('Error Boxplots for GPS vs PCMF and GPS vs UKF PCMF Points')\n",
    "# Adjust layout to prevent overlapping title\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "plt.show()\n",
    "\n",
    "# Calculate RMSE for X and Y directions and combined Euclidean distance for GPS vs PCMF and GPS vs UKF\n",
    "rmse_x_pcmf = np.sqrt(mean_squared_error(data['gps/local_fix_x'], data['path_points_x']))\n",
    "rmse_y_pcmf = np.sqrt(mean_squared_error(data['gps/local_fix_y'], data['path_points_y']))\n",
    "rmse_euclidean_pcmf = np.sqrt(mean_squared_error(data['gps/local_fix_x'], data['path_points_x']) + mean_squared_error(data['gps/local_fix_y'], data['path_points_y']))\n",
    "\n",
    "rmse_x_ukf = np.sqrt(mean_squared_error(data['gps/local_fix_x'], ukf_results[:, 0]))\n",
    "rmse_y_ukf = np.sqrt(mean_squared_error(data['gps/local_fix_y'], ukf_results[:, 2]))\n",
    "rmse_euclidean_ukf = np.sqrt(mean_squared_error(data['gps/local_fix_x'], ukf_results[:, 0]) + mean_squared_error(data['gps/local_fix_y'], ukf_results[:, 2]))\n",
    "\n",
    "print(f\"RMSE X GPS vs PCMF: {rmse_x_pcmf:.2f} meters\")\n",
    "print(f\"RMSE Y GPS vs PCMF: {rmse_y_pcmf:.2f} meters\")\n",
    "print(f\"RMSE Euclidean GPS vs PCMF: {rmse_euclidean_pcmf:.2f} meters\\n\")\n",
    "\n",
    "print(f\"RMSE X GPS vs UKF: {rmse_x_ukf:.2f} meters\")\n",
    "print(f\"RMSE Y GPS vs UKF: {rmse_y_ukf:.2f} meters\")\n",
    "print(f\"RMSE Euclidean GPS vs UKF: {rmse_euclidean_ukf:.2f} meters\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_path = np.array([data['gps/local_fix_x'], data['gps/local_fix_y']]).T\n",
    "pcmf_path = np.array([data['path_points_x'], data['path_points_y']]).T\n",
    "ukf_path = np.array([ukf_results[:, 0], ukf_results[:, 2]]).T\n",
    "camera_path = np.array([data['camera_trace_x'], data['camera_trace_y']]).T\n",
    "\n",
    "# shift gps points 200 m left for a while\n",
    "# gps_path[100:120, 0] = gps_path[100:120, 0] - 50 # brattora test 1\n",
    "# gps_path[50:60, 0] = gps_path[50:60, 0] - 50 # eval_data\n",
    "\n",
    "# scatter those points randomly within 10 meters in x and y\n",
    "# gps_path[100:120, 0] = gps_path[100:120, 0] + np.random.uniform(-10, 10, 20)\n",
    "# gps_path[100:120, 1] = gps_path[100:120, 1] + np.random.uniform(-10, 10, 20)\n",
    "\n",
    "def state_transition(x, dt):\n",
    "    F = np.array([[1, 0, dt, 0],\n",
    "                  [0, 1, 0, dt],\n",
    "                  [0, 0, 1, 0],\n",
    "                  [0, 0, 0, 1]])\n",
    "    return np.dot(F, x)\n",
    "\n",
    "def measurement_function(x):\n",
    "    return x[:2]  # Only position is measured\n",
    "\n",
    "def innovation_check(innovation, threshold):\n",
    "    return np.linalg.norm(innovation) > threshold\n",
    "\n",
    "def fuse_paths(gps_path, kf_path, threshold=30):\n",
    "    dt = 1  # Time step\n",
    "    points = MerweScaledSigmaPoints(n=4, alpha=0.1, beta=2., kappa=0)\n",
    "    ukf = UnscentedKalmanFilter(dim_x=4, dim_z=2, dt=dt, fx=state_transition, hx=measurement_function, points=points)\n",
    "    ukf.Q = np.eye(4) * 0.1  # Process noise\n",
    "    ukf.P = np.eye(4) * 10   # Initial state covariance\n",
    "    ukf.x = np.array([gps_path[0, 0], gps_path[0, 1], 0, 0])  # Initial state from first GPS point\n",
    "\n",
    "    fused_path = []\n",
    "\n",
    "    for i, (gps, kf) in enumerate(zip(gps_path, kf_path)):\n",
    "        # Predict state\n",
    "        ukf.predict()\n",
    "\n",
    "        # Update state with GPS measurement\n",
    "        innovation_gps = gps - ukf.hx(ukf.x)\n",
    "        if innovation_check(innovation_gps, threshold):\n",
    "            # If innovation is large, increase the measurement noise covariance\n",
    "            ukf.R = np.eye(2) * 10000 # Large measurement noise\n",
    "        else:\n",
    "            ukf.R = np.eye(2) * 1 # Normal measurement noise\n",
    "        ukf.update(gps)\n",
    "\n",
    "        # Predict state again before another measurement update\n",
    "        ukf.predict()\n",
    "        \n",
    "        # Update state with KF measurement\n",
    "        innovation_kf = kf - ukf.hx(ukf.x)\n",
    "        if innovation_check(innovation_kf, threshold):\n",
    "            ukf.R = np.eye(2) * 10000\n",
    "        else:\n",
    "            ukf.R = np.eye(2) * 10\n",
    "        ukf.update(kf)\n",
    "\n",
    "        fused_path.append(ukf.x[:2].copy())\n",
    "\n",
    "    return np.array(fused_path)\n",
    "\n",
    "fused_path = fuse_paths(gps_path, ukf_path)\n",
    "\n",
    "# Plotting the fused path\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# ax.scatter(gps_path[:, 0], gps_path[:, 1], label='GPS Path', color=gps_color, s=5)\n",
    "ax.plot(gps_path[:, 0], gps_path[:, 1], color=gps_color, label='GPS Path', linewidth=2)\n",
    "ax.scatter(pcmf_path[:, 0], pcmf_path[:, 1], label='PCMF Path Points', color=pcmf_color, s=10)\n",
    "ax.plot(ukf_results[:, 0], ukf_results[:, 2], color=ukf_color, label=\"UKF Filtered Path Points\")\n",
    "ax.plot(fused_path[:, 0], fused_path[:, 1], color='limegreen', label=\"Fused Path\", linewidth=2)\n",
    "# ax.plot(camera_path[:, 0], camera_path[:, 1], color='red', label=\"Camera Path\", linewidth=2)\n",
    "# ax.scatter(map_data[:, 0], map_data[:, 1], color='orange', s=map_dot_size, label='Reference Map')\n",
    "ax.set_xlabel(\"East [m]\")\n",
    "ax.set_ylabel(\"North [m]\")\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(True, linestyle='--' )\n",
    "ax.set_xlim(gps_path[:, 0].min() - 10, gps_path[:, 0].max() + 10)\n",
    "ax.set_ylim(gps_path[:, 1].min() - 10, gps_path[:, 1].max() + 10)\n",
    "# ax.axis('equal')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# print(\"elapsed time: \", data['timestamp'].iloc[-1], \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "def comparison_plots(directory):\n",
    "    # List all CSV files in the specified directory\n",
    "    csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "\n",
    "    # boxplot errors for each file in the same plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    for idx, file in enumerate(csv_files):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        temp_data = pd.read_csv(file_path)\n",
    "        x_data = temp_data[['gps/local_fix_x', 'path_points_x']].dropna()\n",
    "        y_data = temp_data[['gps/local_fix_y', 'path_points_y']].dropna()\n",
    "        errors = np.sqrt((x_data['gps/local_fix_x'] - x_data['path_points_x'])**2 + (y_data['gps/local_fix_y'] - y_data['path_points_y'])**2)\n",
    "        lower, upper = iqr_limits(errors)\n",
    "        ax.boxplot(errors, patch_artist=True, positions=[idx], widths=0.6, boxprops=dict(facecolor='none'))\n",
    "        # ax.set_xticks(range(len(csv_files)))\n",
    "        ax.set_xticklabels(\"Test \" + str(i) for i in range(1, len(csv_files) + 1))\n",
    "        # ax.set_xticklabels((str(i) for i in csv_files), rotation=45, ha='right')\n",
    "        # ax.set_title('Euclidean Errors for PCMF Path of All Tests')\n",
    "        # ax.set_ylim(-5, 110)\n",
    "        ax.set_ylabel('Euclidean Error [m]')\n",
    "        # jitter = np.random.uniform(-0.3, 0.3, len(errors))\n",
    "        # ax.scatter(np.full(len(errors), idx) + jitter, errors, alpha=0.5)\n",
    "    plt.suptitle('a)', fontsize=20, x=0.5, y=0.05)\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 1])\n",
    "    plt.show()\n",
    "    \n",
    "    # run and boxplot UKF errors for each file\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "    for idx, file in enumerate(csv_files):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        temp_data = pd.read_csv(file_path)\n",
    "        ukf_results, covariances = UKF(temp_data)\n",
    "        errors = np.sqrt((temp_data['gps/local_fix_x'] - ukf_results[:, 0])**2 + (temp_data['gps/local_fix_y'] - ukf_results[:, 2])**2)\n",
    "        lower, upper = iqr_limits(errors)\n",
    "        ax.boxplot(errors, patch_artist=True, positions=[idx], widths=0.6, boxprops=dict(facecolor='none'))\n",
    "        ax.set_xticks(range(len(csv_files)))\n",
    "        ax.set_xticklabels((\"Test \" + str(i) for i in range(1, len(csv_files) + 1)))\n",
    "        ax.set_title('Euclidean Errors for UKF Path of All Tests')\n",
    "        ax.set_ylabel('Euclidean Error [m]')\n",
    "        # jitter = np.random.uniform(-0.3, 0.3, len(errors))\n",
    "        # ax.scatter(np.full(len(errors), idx) + jitter, errors, alpha=0.5)\n",
    "\n",
    "    plt.suptitle('b)', fontsize=20, x=0.5, y=0.05)\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 1])\n",
    "    plt.show()\n",
    "\n",
    "    # bar plot of RMSE for each test for PCMF and UKF\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    rmse_pcmf = []\n",
    "    rmse_ukf = []\n",
    "\n",
    "    for idx, file in enumerate(csv_files):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        temp_data = pd.read_csv(file_path)\n",
    "        ukf_results, covariances = UKF(temp_data)\n",
    "        errors_pcmf = np.sqrt((temp_data['gps/local_fix_x'] - temp_data['path_points_x'])**2 + (temp_data['gps/local_fix_y'] - temp_data['path_points_y'])**2)\n",
    "        errors_ukf = np.sqrt((temp_data['gps/local_fix_x'] - ukf_results[:, 0])**2 + (temp_data['gps/local_fix_y'] - ukf_results[:, 2])**2)\n",
    "        rmse_pcmf.append(np.sqrt(np.mean(errors_pcmf**2)))\n",
    "        rmse_ukf.append(np.sqrt(np.mean(errors_ukf**2)))\n",
    "        # print RMSE for each test\n",
    "        print(f\"Test {idx + 1} \\n  RMSE PCMF: {rmse_pcmf[-1]:.2f} meters\")\n",
    "        print(f\"  RMSE UKF: {rmse_ukf[-1]:.2f} meters\")\n",
    "\n",
    "\n",
    "    ax.bar(np.arange(len(csv_files)) - 0.2, rmse_pcmf, width=0.4, label='PCMF Path', color=pcmf_color)\n",
    "    ax.bar(np.arange(len(csv_files)) + 0.2, rmse_ukf, width=0.4, label='UKF Path', color=ukf_color)\n",
    "    ax.set_xticks(range(len(csv_files)))\n",
    "    ax.set_xticklabels((\"Test \" + str(i) for i in range(1, len(csv_files) + 1)))\n",
    "    # ax.set_title('RMSE for PCMF and UKF Paths of All Tests')\n",
    "    ax.set_ylabel('Euclidean RMSE [m]')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Specify the directory containing the CSV files, aka this directory\n",
    "directory = '.'\n",
    "comparison_plots(directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sensor Fusion with Fiducial Markers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload to avoid accumulating data\n",
    "gps_path = np.array([data['gps/local_fix_x'], data['gps/local_fix_y']]).T\n",
    "pcmf_path = np.array([data['path_points_x'], data['path_points_y']]).T\n",
    "ukf_path = np.array([ukf_results[:, 0], ukf_results[:, 2]]).T\n",
    "camera_path = np.array([data['camera_trace_x'], data['camera_trace_y']]).T\n",
    "\n",
    "# State transition and measurement functions as previously defined\n",
    "def state_transition(x, dt):\n",
    "    F = np.array([[1, 0, dt, 0],\n",
    "                  [0, 1, 0, dt],\n",
    "                  [0, 0, 1, 0],\n",
    "                  [0, 0, 0, 1]])\n",
    "    return np.dot(F, x)\n",
    "\n",
    "def measurement_function(x):\n",
    "    return x[:2]\n",
    "\n",
    "def innovation_check(innovation, threshold):\n",
    "    return np.linalg.norm(innovation) > threshold\n",
    "\n",
    "def fuse_paths(gps_path, pcmf_path, camera_path, threshold=30):\n",
    "    dt = 1  # Time step\n",
    "    points = MerweScaledSigmaPoints(n=4, alpha=0.1, beta=2., kappa=0)\n",
    "    ukf = UnscentedKalmanFilter(dim_x=4, dim_z=2, dt=dt, fx=state_transition, hx=measurement_function, points=points)\n",
    "    ukf.Q = np.eye(4) * 0.1  # Process noise \n",
    "    ukf.P = np.eye(4) * 10   # Initial state covariance\n",
    "    ukf.x = np.array([gps_path[0, 0], gps_path[0, 1], 0, 0])  # Initial state from first GPS point\n",
    "\n",
    "    fused_path = []\n",
    "\n",
    "    for i, (gps, kf, cam) in enumerate(zip(gps_path, pcmf_path, camera_path)):\n",
    "        ukf.predict()  # Predict state\n",
    "\n",
    "        # Update state with GPS measurement if not NaN\n",
    "        if not np.isnan(gps).any():\n",
    "            innovation_gps = gps - ukf.hx(ukf.x)\n",
    "            if innovation_check(innovation_gps, threshold):\n",
    "                ukf.R = np.eye(2) * 10000  # Large measurement noise\n",
    "            else:\n",
    "                ukf.R = np.eye(2) * 1  # Normal measurement noise\n",
    "            ukf.update(gps)\n",
    "\n",
    "        # Update state with KF measurement if not NaN\n",
    "        if not np.isnan(kf).any():\n",
    "            ukf.predict()  # Predict state again before another measurement update\n",
    "            innovation_kf = kf - ukf.hx(ukf.x)\n",
    "            if innovation_check(innovation_kf, threshold):\n",
    "                ukf.R = np.eye(2) * 10000\n",
    "            else:\n",
    "                ukf.R = np.eye(2) * 10\n",
    "            ukf.update(kf)\n",
    "\n",
    "        # Update state with camera measurement if not NaN\n",
    "        if not np.isnan(cam).any():\n",
    "            ukf.predict()  # Predict state again before another measurement update\n",
    "            innovation_cam = cam - ukf.hx(ukf.x)\n",
    "            if innovation_check(innovation_cam, threshold):\n",
    "                ukf.R = np.eye(2) * 10000\n",
    "            else:\n",
    "                ukf.R = np.eye(2) * 5  # Slightly more trust than KF\n",
    "            ukf.update(cam)\n",
    "\n",
    "        fused_path.append(ukf.x[:2].copy())\n",
    "\n",
    "    return np.array(fused_path)\n",
    "\n",
    "# jamming the gps path for testing\n",
    "# gps_path[50:70, 0] = gps_path[50:70, 0] - 50 # eval_data\n",
    "\n",
    "# remove all ukf_results points after 50 for testing\n",
    "# ukf_results = ukf_results[:50]\n",
    "\n",
    "fused_path_cam = fuse_paths(gps_path, pcmf_path, camera_path)\n",
    "\n",
    "# Plotting the fused path\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# ax.scatter(gps_path[:, 0], gps_path[:, 1], label='GPS Path', color=gps_color, s=5)\n",
    "ax.plot(gps_path[:, 0], gps_path[:, 1], color=gps_color, label='GPS Path', linewidth=2)\n",
    "ax.scatter(pcmf_path[:, 0], pcmf_path[:, 1], label='PCMF Path Points', color=pcmf_color, s=10)\n",
    "# scatter plot camera path in red with black border\n",
    "ax.scatter(camera_path[:, 0], camera_path[:, 1], label='Camera Path Points', color='white', s=15, edgecolors='black')\n",
    "\n",
    "ax.plot(ukf_results[:, 0], ukf_results[:, 2], color=ukf_color, label=\"UKF Filtered Path Points\")\n",
    "ax.plot(fused_path_cam[:, 0], fused_path_cam[:, 1], color='lime', label=\"Fused Path with Camera\", linewidth=2)\n",
    "ax.plot(map_data[:, 0], map_data[:, 1], color=map_color, label='Reference Map')\n",
    "ax.set_xlabel(\"East [m]\")\n",
    "ax.set_ylabel(\"North [m]\")\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(True, linestyle='--' )\n",
    "ax.set_xlim(gps_path[:, 0].min() - 10, gps_path[:, 0].max() + 10)\n",
    "ax.set_ylim(gps_path[:, 1].min() - 10, gps_path[:, 1].max() + 10)\n",
    "# ax.set_xlim(20,50)\n",
    "# ax.set_ylim(-180, -160)\n",
    "# ax.axis('equal')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # box plot of errors, full range and zoomed in to IQR above each other, using orange color\n",
    "# # find iqr range\n",
    "# q1 = np.percentile(errors, 25)\n",
    "# q3 = np.percentile(errors, 75)\n",
    "\n",
    "# box_colors = ['orange']\n",
    "\n",
    "# fig, ax = plt.subplots(2, 1, figsize=(6,4)) \n",
    "# ax[0].boxplot(errors, vert=False, patch_artist=True,\n",
    "#                 boxprops=dict(facecolor=box_colors[0], alpha=0.7),\n",
    "#                 medianprops=dict(color=\"black\"),\n",
    "#                 whiskerprops=dict(color=box_colors[0]),\n",
    "#                 # capprops=dict(color=box_colors[0]),\n",
    "#                 flierprops=dict(markeredgecolor=box_colors[0], marker='o'))\n",
    "# ax[0].set_title('Euclidean Error GNSS vs PCMF path')\n",
    "# ax[0].set_xlabel('Error')\n",
    "# # ax[0].grid(True)\n",
    "\n",
    "# ax[1].boxplot(errors, vert=False, patch_artist=True,\n",
    "#                 boxprops=dict(facecolor=box_colors[0], alpha=0.7),\n",
    "#                 medianprops=dict(color=\"black\"),\n",
    "#                 whiskerprops=dict(color=box_colors[0]),\n",
    "#                 # capprops=dict(color=box_colors[0]),\n",
    "#                 flierprops=dict(markeredgecolor=box_colors[0], marker='o'))\n",
    "# ax[1].set_title('IQR Euclidean Error GNSS vs PCMF path')\n",
    "# ax[1].set_xlabel('Error')\n",
    "# # ax[1].grid(True)\n",
    "# ax[1].set_xlim(q1 - 1.5*(q3-q1), q3 + 1.5*(q3-q1))\n",
    "\n",
    "# plt.tight_layout(h_pad=1.0, pad=0.0, w_pad=0.0)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # histogram of errors\n",
    "# plt.hist(errors, bins=20, density=True, alpha=0.6, color='g')\n",
    "# mu, std = norm.fit(errors)\n",
    "# xmin, xmax = plt.xlim()\n",
    "# x = np.linspace(xmin, xmax, 100)\n",
    "# p = norm.pdf(x, mu, std)\n",
    "# plt.plot(x, p, 'k', linewidth=2)\n",
    "# plt.title(\"Histogram of errors\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Q-Q plot\n",
    "# import scipy.stats as stats\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# stats.probplot(errors, dist=\"norm\", plot=plt)\n",
    "# plt.title(\"Normal Q-Q plot\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformation Plotter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to calculate the 80% confidence interval for normal distribution\n",
    "# def confidence_interval(data, confidence=0.8):\n",
    "#     mean, sigma = np.mean(data), np.std(data)\n",
    "#     h = sigma * norm.ppf((1 + confidence) / 2)\n",
    "#     return mean - h, mean + h\n",
    "\n",
    "# # Set up the subplots\n",
    "# fig, ax = plt.subplots(3, 2, figsize=(18, 15))\n",
    "\n",
    "# # Plots for transformations over time\n",
    "# ax[0, 0].plot(data['timestamp'].to_numpy(), data['transformation_history_x'].to_numpy(), label='X without EKF', color='orange')\n",
    "# ax[0, 0].plot(data['timestamp'].to_numpy(), data['EKF_transformation_history_x'].to_numpy(), label='X with EKF', color='green')\n",
    "# ax[1, 0].plot(data['timestamp'].to_numpy(), data['transformation_history_y'].to_numpy(), label='Y without EKF', color='orange')\n",
    "# ax[1, 0].plot(data['timestamp'].to_numpy(), data['EKF_transformation_history_y'].to_numpy(), label='Y with EKF', color='green')\n",
    "# ax[2, 0].plot(data['timestamp'].to_numpy(), data['transformation_history_rotation'].to_numpy(), label='Theta without EKF', color='orange')\n",
    "# ax[2, 0].plot(data['timestamp'].to_numpy(), data['EKF_transformation_history_rotation'].to_numpy(), label='Theta with EKF', color='green')\n",
    "\n",
    "# # Set labels and titles for left side plots\n",
    "# for i in range(3):\n",
    "#     ax[i, 0].set_xlabel('Timestamp')\n",
    "#     ax[i, 0].set_ylabel(['X Position', 'Y Position', 'Theta'][i])\n",
    "#     ax[i, 0].legend()\n",
    "#     ax[i, 0].grid(True)\n",
    "\n",
    "# # Plots for transformation distributions\n",
    "# for i, col in enumerate(['transformation_history_x', 'transformation_history_y', 'transformation_history_rotation']):\n",
    "#     data_col = data[col].dropna().to_numpy()\n",
    "#     ekf_col = data[f'EKF_{col}'].dropna().to_numpy()\n",
    "\n",
    "#     # Calculate normal distribution fit\n",
    "#     mu, std = norm.fit(data_col)\n",
    "#     mu_ekf, std_ekf = norm.fit(ekf_col)\n",
    "\n",
    "#     # Create a dense range of x values for plotting the PDF\n",
    "#     xmin, xmax = min(data_col.min(), ekf_col.min()), max(data_col.max(), ekf_col.max())\n",
    "#     x = np.linspace(xmin, xmax, 1000)\n",
    "#     p = norm.pdf(x, mu, std)\n",
    "#     p_ekf = norm.pdf(x, mu_ekf, std_ekf)\n",
    "\n",
    "#     # Manually normalize the PDF so that the integral is exactly 1\n",
    "#     p /= np.trapz(p, x)\n",
    "#     p_ekf /= np.trapz(p_ekf, x)\n",
    "\n",
    "#     # Plot the distributions\n",
    "#     ax[i, 1].plot(x, p, label=f'{col} Normalized', color='orange')\n",
    "#     ax[i, 1].plot(x, p_ekf, label=f'EKF_{col} Normalized', color='green')\n",
    "\n",
    "#     # Plotting the 80% confidence interval shading\n",
    "#     low, high = confidence_interval(data_col, confidence=0.95)\n",
    "#     low_ekf, high_ekf = confidence_interval(ekf_col, confidence=0.95)\n",
    "#     ax[i, 1].fill_between(x, p, where=(x > low) & (x < high), color='orange', alpha=0.2)\n",
    "#     ax[i, 1].fill_between(x, p_ekf, where=(x > low_ekf) & (x < high_ekf), color='green', alpha=0.2)\n",
    "\n",
    "#     # Set labels and grid\n",
    "#     ax[i, 1].set_xlabel(['X Position', 'Y Position', 'Theta'][i])\n",
    "#     ax[i, 1].set_ylabel('Probability Density')\n",
    "#     ax[i, 1].legend()\n",
    "#     ax[i, 1].grid(True)\n",
    "\n",
    "# fig.suptitle('Transformations with Normal Distribution Approximation', fontsize=16)\n",
    "# plt.subplots_adjust(top=0.95)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.stats import gaussian_kde\n",
    "# from sklearn.utils import resample\n",
    "\n",
    "# # Function to calculate the confidence interval using the bootstrap method\n",
    "# def bootstrap_confidence_interval(data, confidence=0.8, n_iterations=1000):\n",
    "#     bootstrap_samples = np.array([np.mean(resample(data)) for _ in range(n_iterations)])\n",
    "#     alpha = 1 - confidence\n",
    "#     lower_percentile = 100 * alpha / 2\n",
    "#     upper_percentile = 100 * (1 - alpha / 2)\n",
    "#     lower_bound = np.percentile(bootstrap_samples, lower_percentile)\n",
    "#     upper_bound = np.percentile(bootstrap_samples, upper_percentile)\n",
    "#     return lower_bound, upper_bound\n",
    "\n",
    "# # Set up the subplots\n",
    "# fig, ax = plt.subplots(3, 2, figsize=(18, 15))\n",
    "\n",
    "# # Plots for transformations over time\n",
    "# ax[0, 0].plot(data['timestamp'].to_numpy(), data['transformation_history_x'].to_numpy(), label='X without EKF', color='orange')\n",
    "# ax[0, 0].plot(data['timestamp'].to_numpy(), data['EKF_transformation_history_x'].to_numpy(), label='X with EKF', color='green')\n",
    "# ax[1, 0].plot(data['timestamp'].to_numpy(), data['transformation_history_y'].to_numpy(), label='Y without EKF', color='orange')\n",
    "# ax[1, 0].plot(data['timestamp'].to_numpy(), data['EKF_transformation_history_y'].to_numpy(), label='Y with EKF', color='green')\n",
    "# ax[2, 0].plot(data['timestamp'].to_numpy(), data['transformation_history_rotation'].to_numpy(), label='Theta without EKF', color='orange')\n",
    "# ax[2, 0].plot(data['timestamp'].to_numpy(), data['EKF_transformation_history_rotation'].to_numpy(), label='Theta with EKF', color='green')\n",
    "\n",
    "# # Set labels and titles for left side plots\n",
    "# for i in range(3):\n",
    "#     ax[i, 0].set_xlabel('Timestamp')\n",
    "#     ax[i, 0].set_ylabel(['X Position', 'Y Position', 'Theta'][i])\n",
    "#     ax[i, 0].legend()\n",
    "#     ax[i, 0].grid(True)\n",
    "\n",
    "# # Plots for transformation distributions\n",
    "# for i, col in enumerate(['transformation_history_x', 'transformation_history_y', 'transformation_history_rotation']):\n",
    "#     data_col = data[col].dropna().to_numpy()\n",
    "#     ekf_col = data[f'EKF_{col}'].dropna().to_numpy()\n",
    "\n",
    "#     # Create a dense range of x values for plotting the PDF\n",
    "#     xmin, xmax = min(data_col.min(), ekf_col.min()), max(data_col.max(), ekf_col.max())\n",
    "#     x = np.linspace(xmin, xmax, 1000)\n",
    "\n",
    "#     # Use kernel density estimation for a smooth estimate of the PDF\n",
    "#     kde = gaussian_kde(data_col)\n",
    "#     kde_ekf = gaussian_kde(ekf_col)\n",
    "#     p = kde(x)\n",
    "#     p_ekf = kde_ekf(x)\n",
    "\n",
    "#     # Plot the distributions\n",
    "#     ax[i, 1].plot(x, p, label=f'{col} Density Estimate', color='orange')\n",
    "#     ax[i, 1].plot(x, p_ekf, label=f'EKF_{col} Density Estimate', color='green')\n",
    "\n",
    "#     # Plotting the confidence interval shading using bootstrap\n",
    "#     low, high = bootstrap_confidence_interval(data_col, confidence=0.95)\n",
    "#     low_ekf, high_ekf = bootstrap_confidence_interval(ekf_col, confidence=0.95)\n",
    "#     ax[i, 1].fill_between(x, p, where=(x > low) & (x < high), color='orange', alpha=0.2)\n",
    "#     ax[i, 1].fill_between(x, p_ekf, where=(x > low_ekf) & (x < high_ekf), color='green', alpha=0.2)\n",
    "\n",
    "#     # Set labels and grid\n",
    "#     ax[i, 1].set_xlabel(['X Position', 'Y Position', 'Theta'][i])\n",
    "#     ax[i, 1].set_ylabel('Probability Density')\n",
    "#     ax[i, 1].legend()\n",
    "#     ax[i, 1].grid(True)\n",
    "\n",
    "# fig.suptitle('Transformation Density Estimate with Bootstrap Confidence Interval', fontsize=16)\n",
    "# plt.subplots_adjust(top=0.95)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from scipy.stats import gaussian_kde\n",
    "\n",
    "# # Set up the subplots\n",
    "# fig, ax = plt.subplots(3, 2, figsize=(18, 15))\n",
    "\n",
    "# # Plots for transformations over time\n",
    "# ax[0, 0].plot(data['timestamp'].to_numpy(), data['transformation_history_x'].to_numpy(), label='X without EKF', color='orange')\n",
    "# ax[0, 0].plot(data['timestamp'].to_numpy(), data['EKF_transformation_history_x'].to_numpy(), label='X with EKF', color='green')\n",
    "# ax[1, 0].plot(data['timestamp'].to_numpy(), data['transformation_history_y'].to_numpy(), label='Y without EKF', color='orange')\n",
    "# ax[1, 0].plot(data['timestamp'].to_numpy(), data['EKF_transformation_history_y'].to_numpy(), label='Y with EKF', color='green')\n",
    "# ax[2, 0].plot(data['timestamp'].to_numpy(), data['transformation_history_rotation'].to_numpy(), label='Theta without EKF', color='orange')\n",
    "# ax[2, 0].plot(data['timestamp'].to_numpy(), data['EKF_transformation_history_rotation'].to_numpy(), label='Theta with EKF', color='green')\n",
    "\n",
    "# # Set labels and titles for left side plots\n",
    "# for i in range(3):\n",
    "#     ax[i, 0].set_xlabel('Timestamp')\n",
    "#     ax[i, 0].set_ylabel(['X Position', 'Y Position', 'Theta'][i])\n",
    "#     ax[i, 0].legend()\n",
    "#     ax[i, 0].grid(True)\n",
    "\n",
    "# # Plots for transformation distributions using box plots\n",
    "# for i, col in enumerate(['transformation_history_x', 'transformation_history_y', 'transformation_history_rotation']):\n",
    "#     data_col = data[col].dropna().to_numpy()\n",
    "#     ekf_col = data[f'EKF_{col}'].dropna().to_numpy()\n",
    "\n",
    "#     # Define box properties for each dataset\n",
    "#     box_colors = ['orange', 'green']  # Colors for the boxes\n",
    "\n",
    "#     # Plot the box plots for each dataset separately\n",
    "#     box1 = ax[i, 1].boxplot(data_col, positions=[1], widths=0.6, patch_artist=True,\n",
    "#                             boxprops=dict(facecolor=box_colors[0]),\n",
    "#                             medianprops=dict(color=\"black\"),\n",
    "#                             whiskerprops=dict(color=box_colors[0]),\n",
    "#                             capprops=dict(color=box_colors[0]),\n",
    "#                             flierprops=dict(markeredgecolor=box_colors[0], marker='o'))\n",
    "    \n",
    "#     box2 = ax[i, 1].boxplot(ekf_col, positions=[2], widths=0.6, patch_artist=True,\n",
    "#                             boxprops=dict(facecolor=box_colors[1]),\n",
    "#                             medianprops=dict(color=\"black\"),\n",
    "#                             whiskerprops=dict(color=box_colors[1]),\n",
    "#                             capprops=dict(color=box_colors[1]),\n",
    "#                             flierprops=dict(markeredgecolor=box_colors[1], marker='o'))\n",
    "\n",
    "#     # Set labels and titles for right side plots\n",
    "#     ax[i, 1].set_xticks([1, 2])\n",
    "#     ax[i, 1].set_xticklabels(['Without EKF', 'With EKF'])\n",
    "#     ax[i, 1].set_title(f'Distribution of {col}')\n",
    "#     ax[i, 1].grid(True)\n",
    "\n",
    "# # Adjust layout and display the plot\n",
    "# fig.suptitle('Transformation History and Distribution Analysis', fontsize=16)\n",
    "# plt.subplots_adjust(top=0.95)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
